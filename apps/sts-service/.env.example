# STS Service Configuration Template
# Copy to .env and customize for your environment

# =============================================================================
# Service Configuration
# =============================================================================

# Server Config
STS_HOST=0.0.0.0
STS_PORT=3000
LOG_LEVEL=INFO

# Container Config
STS_CONTAINER_NAME=sts-service
STS_SERVICE_IMAGE=sts-service:latest
BUILD_ENV=production

# =============================================================================
# Processing Configuration
# =============================================================================

# Device (cpu or cuda)
# - cpu: CPU-only processing (macOS, development)
# - cuda: GPU acceleration (Linux with NVIDIA GPU)
DEVICE=cpu

# ASR Model (Whisper)
# - tiny: Fastest, least accurate (~75MB, ~1GB RAM, ~10x realtime CPU)
# - base: Fast, good accuracy (~150MB, ~1GB RAM, ~7x realtime CPU)
# - small: Balanced (~500MB, ~2GB RAM, ~4x realtime CPU)
# - medium: High accuracy (~1.5GB, ~5GB RAM, ~2x realtime CPU)
# - large: Best accuracy (~3GB, ~10GB RAM, ~1x realtime CPU)
ASR_MODEL=base

# TTS Provider
# - coqui: Real TTS synthesis (slower, production)
# - mock: Mock TTS for testing (instant)
TTS_PROVIDER=coqui

# Translation Provider
# - deepl: Real translation (requires DEEPL_AUTH_KEY)
# - mock: Mock translation for testing
TRANSLATION_PROVIDER=deepl

# =============================================================================
# API Keys (Required for Production)
# =============================================================================

# DeepL API Key (required if TRANSLATION_PROVIDER=deepl)
# Get your key at: https://www.deepl.com/pro-api
DEEPL_AUTH_KEY=8e373354-4ca7-4fec-b563-93b2fa6930cc:fx

# =============================================================================
# Performance Tuning
# =============================================================================

# Concurrent Sessions
MAX_CONCURRENT_SESSIONS=10

# Model Cache Directory (for Whisper models)
MODEL_CACHE_DIR=/app/.cache

# Socket.IO Configuration
WS_MAX_CONNECTIONS=50
WS_MAX_BUFFER_SIZE=52428800  # 50MB
WS_PING_INTERVAL=25          # seconds
WS_PING_TIMEOUT=10           # seconds

# =============================================================================
# Resource Limits (Docker Compose)
# =============================================================================

# CPU Limits
STS_CPU_LIMIT=4.0           # Maximum CPUs
STS_CPU_RESERVATION=2.0     # Minimum CPUs

# Memory Limits
STS_MEMORY_LIMIT=8G         # Maximum memory
STS_MEMORY_RESERVATION=4G   # Minimum memory

# GPU Configuration (uncomment for NVIDIA GPU)
# GPU_COUNT=1

# =============================================================================
# Health Check Configuration
# =============================================================================

HEALTHCHECK_INTERVAL=10s
HEALTHCHECK_TIMEOUT=5s
HEALTHCHECK_RETRIES=3
HEALTHCHECK_START_PERIOD=60s  # Allow time for model loading

# =============================================================================
# Logging Configuration
# =============================================================================

LOG_MAX_SIZE=10m
LOG_MAX_FILES=3

# =============================================================================
# Network Configuration
# =============================================================================

NETWORK_NAME=sts-network

# =============================================================================
# Volume Configuration
# =============================================================================

MODEL_CACHE_VOLUME_NAME=sts-model-cache

# Optional: Custom config directory
# CONFIG_DIR=./config

# =============================================================================
# Environment-Specific Examples
# =============================================================================

# Development (macOS, CPU-only):
# DEVICE=cpu
# ASR_MODEL=tiny
# TTS_PROVIDER=mock
# TRANSLATION_PROVIDER=mock

# E2E Testing (CI/CD):
# DEVICE=cpu
# ASR_MODEL=tiny
# TTS_PROVIDER=mock
# TRANSLATION_PROVIDER=mock
# STS_CONTAINER_NAME=e2e-sts-service

# Production (Linux, GPU):
# DEVICE=cuda
# ASR_MODEL=medium
# TTS_PROVIDER=coqui
# TRANSLATION_PROVIDER=deepl
# DEEPL_AUTH_KEY=your-production-key
# GPU_COUNT=1
